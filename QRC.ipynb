{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "QRC.ipynb",
      "history_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMGUrRzNk3SoqgfZUdbarAK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Panperception/QKD/blob/main/QRC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AI-Assisted QKD: Enhancing Security & Efficiency – Python Simulation Guide\n",
        "This project will focus on integrating Machine Learning (ML) with Quantum Key Distribution (QKD) to improve security, efficiency, and error correction. The implementation will involve:\n",
        "\n",
        "Simulating a QKD system (e.g., BB84 protocol).\n",
        "Generating a quantum channel with noise to model realistic conditions.\n",
        "Applying AI/ML models to enhance security, key reconciliation, and error correction.\n",
        "\n",
        "### Initialization:"
      ],
      "metadata": {
        "id": "ZSVfI2SIshTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip uninstall qiskit\n",
        "!pip install pyqmc\n",
        "!pip install qiskit\n",
        "!pip install qiskit-aer\n",
        "!pip install qiskit-algorithms\n",
        "!pip install qiskit-nature\n",
        "!pip install qutip\n",
        "!pip install ase\n",
        "!pip install scipy\n",
        "!nvcc --version"
      ],
      "metadata": {
        "id": "8QJMbule4KQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac45541-bdb4-4888-bdc8-0320f0a6a666"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyqmc\n",
            "  Downloading pyqmc-0.6.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyqmc) (1.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pyqmc) (2.2.2)\n",
            "Collecting pyscf (from pyqmc)\n",
            "  Downloading pyscf-2.8.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from pyqmc) (3.12.1)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from h5py->pyqmc) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pyqmc) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pyqmc) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pyqmc) (2025.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyscf->pyqmc) (75.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->pyqmc) (1.17.0)\n",
            "Downloading pyqmc-0.6.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyscf-2.8.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyscf, pyqmc\n",
            "Successfully installed pyqmc-0.6.0 pyscf-2.8.0\n",
            "Collecting qiskit\n",
            "  Downloading qiskit-1.4.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.13.1)\n",
            "Collecting dill>=0.3 (from qiskit)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.8.2)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit) (4.12.2)\n",
            "Collecting symengine<0.14,>=0.11 (from qiskit)\n",
            "  Downloading symengine-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit)\n",
            "  Downloading pbr-6.1.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit) (75.1.0)\n",
            "Downloading qiskit-1.4.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.4.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symengine-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.1-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: symengine, rustworkx, pbr, dill, stevedore, qiskit\n",
            "Successfully installed dill-0.3.9 pbr-6.1.1 qiskit-1.4.0 rustworkx-0.16.0 stevedore-5.4.1 symengine-0.13.0\n",
            "Collecting qiskit-aer\n",
            "  Downloading qiskit_aer-0.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: qiskit>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (1.13.1)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (5.9.5)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (0.16.0)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (0.3.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (4.12.2)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.11/dist-packages (from qiskit>=1.1.0->qiskit-aer) (0.13.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit>=1.1.0->qiskit-aer) (1.17.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore>=3.0.0->qiskit>=1.1.0->qiskit-aer) (6.1.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit>=1.1.0->qiskit-aer) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit>=1.1.0->qiskit-aer) (75.1.0)\n",
            "Downloading qiskit_aer-0.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: qiskit-aer\n",
            "Successfully installed qiskit-aer-0.16.1\n",
            "Collecting qiskit-algorithms\n",
            "  Downloading qiskit_algorithms-0.3.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: qiskit>=0.44 in /usr/local/lib/python3.11/dist-packages (from qiskit-algorithms) (1.4.0)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.11/dist-packages (from qiskit-algorithms) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from qiskit-algorithms) (1.26.4)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=0.44->qiskit-algorithms) (0.16.0)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit>=0.44->qiskit-algorithms) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit>=0.44->qiskit-algorithms) (0.3.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=0.44->qiskit-algorithms) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=0.44->qiskit-algorithms) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit>=0.44->qiskit-algorithms) (4.12.2)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.11/dist-packages (from qiskit>=0.44->qiskit-algorithms) (0.13.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit>=0.44->qiskit-algorithms) (1.17.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore>=3.0.0->qiskit>=0.44->qiskit-algorithms) (6.1.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit>=0.44->qiskit-algorithms) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit>=0.44->qiskit-algorithms) (75.1.0)\n",
            "Downloading qiskit_algorithms-0.3.1-py3-none-any.whl (310 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: qiskit-algorithms\n",
            "Successfully installed qiskit-algorithms-0.3.1\n",
            "Collecting qiskit-nature\n",
            "  Downloading qiskit_nature-0.7.2-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: qiskit>=0.44 in /usr/local/lib/python3.11/dist-packages (from qiskit-nature) (1.4.0)\n",
            "Requirement already satisfied: qiskit-algorithms>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from qiskit-nature) (0.3.1)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.11/dist-packages (from qiskit-nature) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from qiskit-nature) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.11/dist-packages (from qiskit-nature) (5.9.5)\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-nature) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit-nature) (4.12.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from qiskit-nature) (3.12.1)\n",
            "Requirement already satisfied: rustworkx>=0.12 in /usr/local/lib/python3.11/dist-packages (from qiskit-nature) (0.16.0)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit>=0.44->qiskit-nature) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit>=0.44->qiskit-nature) (0.3.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=0.44->qiskit-nature) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=0.44->qiskit-nature) (5.4.1)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.11/dist-packages (from qiskit>=0.44->qiskit-nature) (0.13.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit>=0.44->qiskit-nature) (1.17.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore>=3.0.0->qiskit>=0.44->qiskit-nature) (6.1.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit>=0.44->qiskit-nature) (1.3.0)\n",
            "Downloading qiskit_nature-0.7.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: qiskit-nature\n",
            "Successfully installed qiskit-nature-0.7.2\n",
            "Collecting qutip\n",
            "  Downloading qutip-5.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from qutip) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from qutip) (1.13.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from qutip) (24.2)\n",
            "Downloading qutip-5.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.1/30.1 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: qutip\n",
            "Successfully installed qutip-5.1.1\n",
            "Collecting ase\n",
            "  Downloading ase-3.24.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from ase) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from ase) (1.13.1)\n",
            "Requirement already satisfied: matplotlib>=3.3.4 in /usr/local/lib/python3.11/dist-packages (from ase) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->ase) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->ase) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->ase) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->ase) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->ase) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->ase) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->ase) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->ase) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.4->ase) (1.17.0)\n",
            "Downloading ase-3.24.0-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ase\n",
            "Successfully installed ase-3.24.0\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy) (1.26.4)\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# from qiskit import QuantumCircuit, execute\n",
        "# import qiskit_aer as Aer\n",
        "from qiskit.visualization import array_to_latex, plot_bloch_vector, plot_bloch_multivector, plot_state_qsphere, plot_state_city\n",
        "from qiskit import QuantumRegister, ClassicalRegister, QuantumCircuit, transpile\n",
        "from qiskit_aer import AerSimulator, Aer\n",
        "\n",
        "from qiskit_nature.second_q.formats.molecule_info import MoleculeInfo\n",
        "from qiskit_nature.units import DistanceUnit\n",
        "from qiskit_nature.second_q.mappers import ParityMapper, JordanWignerMapper, BravyiKitaevMapper\n",
        "from qiskit_nature.second_q.properties import ParticleNumber\n",
        "from qiskit_nature.second_q.transformers import ActiveSpaceTransformer, FreezeCoreTransformer\n",
        "from qiskit_nature import settings\n",
        "from qiskit.primitives import Sampler, StatevectorSampler\n",
        "from qiskit_algorithms import HamiltonianPhaseEstimation, PhaseEstimation\n",
        "from qiskit.primitives import Estimator\n",
        "from qiskit_algorithms.optimizers import SLSQP, SPSA, QNSPSA\n",
        "from qiskit_nature.second_q.circuit.library import UCCSD, HartreeFock\n",
        "from qiskit_algorithms.minimum_eigensolvers import NumPyMinimumEigensolver, VQE\n",
        "from qiskit_nature.second_q.algorithms.ground_state_solvers import GroundStateEigensolver\n",
        "from qiskit.circuit.library import TwoLocal\n",
        "from functools import partial as apply_variation\n",
        "from qiskit.circuit.library import Initialize\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "from qiskit_nature.second_q.mappers import ParityMapper, JordanWignerMapper, BravyiKitaevMapper\n",
        "from qiskit_nature.second_q.properties import ParticleNumber\n",
        "from qiskit_nature.second_q.transformers import ActiveSpaceTransformer, FreezeCoreTransformer\n",
        "from qiskit_nature.second_q.operators import FermionicOp\n",
        "from qiskit_nature.second_q.operators import ElectronicIntegrals\n",
        "from pyscf import gto, scf\n",
        "from ase import Atoms\n",
        "from ase.build import molecule\n",
        "from ase.visualize import view\n",
        "from qiskit_nature.second_q.drivers import PySCFDriver\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import qiskit.quantum_info as qi\n",
        "import os.path\n",
        "# import pyqmc.api as pyq\n",
        "import h5py\n",
        "import cmath\n",
        "import math\n",
        "import scipy.stats as stats\n",
        "import qutip\n",
        "import time, datetime\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "6OxAJWts4Avp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Simulation Setup in Python\n",
        "We will use the following libraries:\n",
        "1. Qiskit for quantum state preparation and measurement.\n",
        "2. NumPy & SciPy for noise modeling and data processing.\n",
        "3. TensorFlow/PyTorch for machine learning models.\n",
        "4. Gym (optional) for reinforcement learning (RL).\n"
      ],
      "metadata": {
        "id": "L9XPEgJYs4iM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Simulating QKD (BB84 Protocol)\n",
        "BB84 is a widely used QKD protocol where Alice sends qubits in random bases, and Bob measures them in a matching or mismatching basis.\n",
        "\n",
        "Basic BB84 Implementation:"
      ],
      "metadata": {
        "id": "N5ffn0tIt2Uc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2V462oL7r7_Y"
      },
      "outputs": [],
      "source": [
        "def generate_bb84_bits(n):\n",
        "    \"\"\"Generate random bit string and random bases for Alice\"\"\"\n",
        "    bits = np.random.randint(0, 2, n)\n",
        "    bases = np.random.randint(0, 2, n)  # 0 = Z basis, 1 = X basis\n",
        "    return bits, bases\n",
        "\n",
        "def prepare_qubits(bits, bases):\n",
        "    \"\"\"Create quantum states based on Alice's bits and bases\"\"\"\n",
        "    qc_list = []\n",
        "    for bit, basis in zip(bits, bases):\n",
        "        qc = QuantumCircuit(1, 1)\n",
        "        if basis == 1:\n",
        "            qc.h(0)  # Apply Hadamard if in X basis\n",
        "        if bit == 1:\n",
        "            qc.x(0)  # Apply X gate if bit is 1\n",
        "        qc_list.append(qc)\n",
        "    return qc_list\n",
        "\n",
        "def measure_qubits(qc_list, bases):\n",
        "    \"\"\"Bob measures the qubits\"\"\"\n",
        "    results = []\n",
        "    backend = Aer.get_backend('aer_simulator')\n",
        "    for qc, basis in zip(qc_list, bases):\n",
        "        if basis == 1:\n",
        "            qc.h(0)  # Apply Hadamard back if measuring in X basis\n",
        "        qc.measure(0, 0)\n",
        "        result = backend.run(qc, shots=10).result()\n",
        "        measured_bit = int(list(result.get_counts().keys())[0])  # Extract bit\n",
        "        results.append(measured_bit)\n",
        "    return results\n",
        "\n",
        "# Simulate BB84\n",
        "n = 100\n",
        "alice_bits, alice_bases = generate_bb84_bits(n)\n",
        "qc_list = prepare_qubits(alice_bits, alice_bases)\n",
        "bob_bases = np.random.randint(0, 2, n)\n",
        "bob_measurements = measure_qubits(qc_list, bob_bases)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. AI-Assisted Attack Detection in Noisy Quantum Channels\n",
        "### Step 2: Simulating a Quantum Channel with Noise\n",
        "We simulate an intercept-resend attack or decoherence noise using depolarizing channels."
      ],
      "metadata": {
        "id": "fr_nEJRvt-Q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit_aer.noise import NoiseModel, errors\n",
        "\n"
      ],
      "metadata": {
        "id": "a76SpsFM4hCX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_noise_model():\n",
        "    \"\"\"Define a depolarizing noise model to simulate an eavesdropper\"\"\"\n",
        "    noise_model = NoiseModel()\n",
        "    error = errors.depolarizing_error(0.05, 1)  # 5% depolarization probability\n",
        "    noise_model.add_all_qubit_quantum_error(error, ['measure'])\n",
        "    return noise_model\n",
        "\n",
        "def simulate_noisy_bb84(qc_list, bases):\n",
        "    \"\"\"Simulate Bob's measurement with a noisy quantum channel\"\"\"\n",
        "    results = []\n",
        "    backend = Aer.get_backend('aer_simulator')\n",
        "    noise_model = create_noise_model()\n",
        "    for qc, basis in zip(qc_list, bases):\n",
        "        if basis == 1:\n",
        "            qc.h(0)\n",
        "        qc.measure(0, 0)\n",
        "        result = backend.run(qc, noise_model=noise_model, shots=10).result()\n",
        "        measured_bit = int(list(result.get_counts().keys())[0])\n",
        "        results.append(measured_bit)\n",
        "    return results\n",
        "\n",
        "bob_noisy_measurements = simulate_noisy_bb84(qc_list, bob_bases)\n"
      ],
      "metadata": {
        "id": "gRTlQbPkuKPe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "V_rBobH9Ys5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Generate dataset\n",
        "def generate_qkd_dataset(samples=1000):\n",
        "    data = []\n",
        "    for _ in range(samples):\n",
        "        # Simulate normal transmission\n",
        "        alice_bits, alice_bases = generate_bb84_bits(100)\n",
        "        qc_list = prepare_qubits(alice_bits, alice_bases)\n",
        "        bob_bases = np.random.randint(0, 2, 100)\n",
        "        bob_measurements = measure_qubits(qc_list, bob_bases)\n",
        "\n",
        "        # Simulate attack/noise\n",
        "        if np.random.rand() < 0.5:  # 50% chance of attack\n",
        "            bob_measurements = simulate_noisy_bb84(qc_list, bob_bases)\n",
        "            label = 1  # Attack\n",
        "        else:\n",
        "            label = 0  # No Attack\n",
        "\n",
        "        qber = np.sum(np.array(alice_bits) != np.array(bob_measurements)) / 100\n",
        "        data.append([qber, label])\n",
        "\n",
        "    return pd.DataFrame(data, columns=['QBER', 'Attack'])\n",
        "\n",
        "df = generate_qkd_dataset()\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['QBER']], df['Attack'], test_size=0.2)\n"
      ],
      "metadata": {
        "id": "xOZkYTwiua1J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Using Machine Learning for Attack Detection\n",
        "An AI model can analyze deviations in the quantum channel noise to detect potential eavesdropping.\n",
        "\n",
        "### Step 3: Training an ML Model for Attack Detection\n",
        "We will train a Neural Network (NN) to differentiate between normal and attack scenarios based on the quantum bit error rate (QBER).\n",
        "\n",
        "Feature Engineering\n",
        "\n",
        "Input: Alice’s and Bob’s measurements, bit mismatch rates.\n",
        "\n",
        "Output: Probability of an eavesdropping attack.\n",
        "\n",
        "Data Preparation"
      ],
      "metadata": {
        "id": "1B71gX9yuTCI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Forest"
      ],
      "metadata": {
        "id": "u3wk2v_rZKVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train an AI Model (Random Forest Classifier)\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"Model Train Accuracy:\", clf.score(X_train, y_train))\n",
        "# Test AI Model\n",
        "print(\"Model Accuracy:\", clf.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHVvar5NZOSH",
        "outputId": "37ee75c8-e737-459e-823e-dde90786c2cf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Train Accuracy: 0.82625\n",
            "Model Accuracy: 0.845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Deep NN - Fully Connected"
      ],
      "metadata": {
        "id": "8d_4vuWYZXzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Build the deep learning model using Keras\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=50, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Making predictions on test data\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "print(\"Sample predictions:\", y_pred[:10].flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsTBIkgbZdAA",
        "outputId": "a114ada6-ada6-4de6-8d38-db249ce5690f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5404 - loss: 0.6944 - val_accuracy: 0.4875 - val_loss: 0.6951\n",
            "Epoch 2/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4794 - loss: 0.6940 - val_accuracy: 0.5125 - val_loss: 0.6915\n",
            "Epoch 3/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4844 - loss: 0.6917 - val_accuracy: 0.5125 - val_loss: 0.6897\n",
            "Epoch 4/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4868 - loss: 0.6901 - val_accuracy: 0.5625 - val_loss: 0.6884\n",
            "Epoch 5/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5427 - loss: 0.6880 - val_accuracy: 0.5500 - val_loss: 0.6862\n",
            "Epoch 6/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5474 - loss: 0.6869 - val_accuracy: 0.6313 - val_loss: 0.6844\n",
            "Epoch 7/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6525 - loss: 0.6860 - val_accuracy: 0.7812 - val_loss: 0.6822\n",
            "Epoch 8/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6757 - loss: 0.6822 - val_accuracy: 0.6938 - val_loss: 0.6789\n",
            "Epoch 9/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6486 - loss: 0.6798 - val_accuracy: 0.7812 - val_loss: 0.6759\n",
            "Epoch 10/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7553 - loss: 0.6747 - val_accuracy: 0.7750 - val_loss: 0.6710\n",
            "Epoch 11/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7283 - loss: 0.6704 - val_accuracy: 0.7812 - val_loss: 0.6660\n",
            "Epoch 12/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7008 - loss: 0.6650 - val_accuracy: 0.7750 - val_loss: 0.6599\n",
            "Epoch 13/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7644 - loss: 0.6602 - val_accuracy: 0.7875 - val_loss: 0.6539\n",
            "Epoch 14/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7696 - loss: 0.6560 - val_accuracy: 0.7812 - val_loss: 0.6457\n",
            "Epoch 15/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7151 - loss: 0.6466 - val_accuracy: 0.7875 - val_loss: 0.6377\n",
            "Epoch 16/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7947 - loss: 0.6381 - val_accuracy: 0.7875 - val_loss: 0.6281\n",
            "Epoch 17/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7771 - loss: 0.6295 - val_accuracy: 0.7812 - val_loss: 0.6169\n",
            "Epoch 18/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7581 - loss: 0.6125 - val_accuracy: 0.8188 - val_loss: 0.6072\n",
            "Epoch 19/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8045 - loss: 0.6089 - val_accuracy: 0.7875 - val_loss: 0.5938\n",
            "Epoch 20/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7673 - loss: 0.5943 - val_accuracy: 0.7875 - val_loss: 0.5816\n",
            "Epoch 21/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7921 - loss: 0.5856 - val_accuracy: 0.8188 - val_loss: 0.5682\n",
            "Epoch 22/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8143 - loss: 0.5682 - val_accuracy: 0.8188 - val_loss: 0.5542\n",
            "Epoch 23/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8103 - loss: 0.5673 - val_accuracy: 0.8188 - val_loss: 0.5419\n",
            "Epoch 24/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7821 - loss: 0.5424 - val_accuracy: 0.8375 - val_loss: 0.5317\n",
            "Epoch 25/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8303 - loss: 0.5342 - val_accuracy: 0.8188 - val_loss: 0.5152\n",
            "Epoch 26/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7874 - loss: 0.5320 - val_accuracy: 0.8250 - val_loss: 0.5078\n",
            "Epoch 27/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8041 - loss: 0.5165 - val_accuracy: 0.8375 - val_loss: 0.4906\n",
            "Epoch 28/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8086 - loss: 0.4936 - val_accuracy: 0.8438 - val_loss: 0.4948\n",
            "Epoch 29/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8295 - loss: 0.4851 - val_accuracy: 0.8188 - val_loss: 0.4679\n",
            "Epoch 30/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8193 - loss: 0.4622 - val_accuracy: 0.8250 - val_loss: 0.4613\n",
            "Epoch 31/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8472 - loss: 0.4608 - val_accuracy: 0.8375 - val_loss: 0.4472\n",
            "Epoch 32/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8213 - loss: 0.4633 - val_accuracy: 0.8438 - val_loss: 0.4445\n",
            "Epoch 33/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8228 - loss: 0.4395 - val_accuracy: 0.8250 - val_loss: 0.4225\n",
            "Epoch 34/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8362 - loss: 0.4154 - val_accuracy: 0.8250 - val_loss: 0.4135\n",
            "Epoch 35/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8118 - loss: 0.4211 - val_accuracy: 0.8250 - val_loss: 0.4078\n",
            "Epoch 36/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8037 - loss: 0.4319 - val_accuracy: 0.8250 - val_loss: 0.4020\n",
            "Epoch 37/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8308 - loss: 0.4128 - val_accuracy: 0.8250 - val_loss: 0.3980\n",
            "Epoch 38/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7983 - loss: 0.4256 - val_accuracy: 0.8250 - val_loss: 0.3899\n",
            "Epoch 39/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8200 - loss: 0.3992 - val_accuracy: 0.8250 - val_loss: 0.3882\n",
            "Epoch 40/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8282 - loss: 0.3930 - val_accuracy: 0.8438 - val_loss: 0.3982\n",
            "Epoch 41/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7990 - loss: 0.4172 - val_accuracy: 0.8250 - val_loss: 0.3815\n",
            "Epoch 42/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8230 - loss: 0.3819 - val_accuracy: 0.8250 - val_loss: 0.3794\n",
            "Epoch 43/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7788 - loss: 0.4354 - val_accuracy: 0.8250 - val_loss: 0.3776\n",
            "Epoch 44/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8180 - loss: 0.3852 - val_accuracy: 0.8250 - val_loss: 0.3754\n",
            "Epoch 45/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8213 - loss: 0.3899 - val_accuracy: 0.8250 - val_loss: 0.3743\n",
            "Epoch 46/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7821 - loss: 0.4285 - val_accuracy: 0.8250 - val_loss: 0.3738\n",
            "Epoch 47/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8315 - loss: 0.3758 - val_accuracy: 0.8438 - val_loss: 0.3777\n",
            "Epoch 48/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8274 - loss: 0.3779 - val_accuracy: 0.8250 - val_loss: 0.3723\n",
            "Epoch 49/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8175 - loss: 0.4160 - val_accuracy: 0.8250 - val_loss: 0.3712\n",
            "Epoch 50/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8165 - loss: 0.3868 - val_accuracy: 0.8438 - val_loss: 0.3830\n",
            "Test Accuracy: 0.8299999833106995\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Sample predictions: [0 1 0 0 1 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LSTM Model"
      ],
      "metadata": {
        "id": "sidEiVysbEXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "timesteps = 20\n",
        "numfeatures = X_train.shape[1]\n",
        "\n",
        "# ------------------------------\n",
        "model = Sequential()\n",
        "# First LSTM layer with return_sequences=True to feed the next LSTM layer.\n",
        "model.add(LSTM(64, input_shape=(timesteps, numfeatures), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "# Second LSTM layer that outputs a fixed-size vector.\n",
        "model.add(LSTM(32))\n",
        "model.add(Dropout(0.2))\n",
        "# Output layer for binary classification.\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# ------------------------------\n",
        "# 3. Train the Model\n",
        "# ------------------------------\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# ------------------------------\n",
        "# 4. Evaluate the Model\n",
        "# ------------------------------\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pFsJtoApWKD4",
        "outputId": "8f8ece6e-40e3-4aa7-b8de-d77ce2c62ba8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m16,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m12,416\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,345\u001b[0m (114.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,345</span> (114.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,345\u001b[0m (114.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,345</span> (114.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.4582 - loss: 0.6932 - val_accuracy: 0.5125 - val_loss: 0.6925\n",
            "Epoch 2/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5136 - loss: 0.6928 - val_accuracy: 0.5125 - val_loss: 0.6923\n",
            "Epoch 3/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6084 - loss: 0.6919 - val_accuracy: 0.4938 - val_loss: 0.6918\n",
            "Epoch 4/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5863 - loss: 0.6915 - val_accuracy: 0.8250 - val_loss: 0.6906\n",
            "Epoch 5/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7476 - loss: 0.6905 - val_accuracy: 0.8375 - val_loss: 0.6890\n",
            "Epoch 6/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7935 - loss: 0.6885 - val_accuracy: 0.8250 - val_loss: 0.6863\n",
            "Epoch 7/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7385 - loss: 0.6857 - val_accuracy: 0.7750 - val_loss: 0.6811\n",
            "Epoch 8/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7112 - loss: 0.6811 - val_accuracy: 0.7812 - val_loss: 0.6735\n",
            "Epoch 9/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6797 - loss: 0.6738 - val_accuracy: 0.8375 - val_loss: 0.6633\n",
            "Epoch 10/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7562 - loss: 0.6613 - val_accuracy: 0.7812 - val_loss: 0.6449\n",
            "Epoch 11/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7423 - loss: 0.6395 - val_accuracy: 0.8375 - val_loss: 0.6230\n",
            "Epoch 12/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7777 - loss: 0.6201 - val_accuracy: 0.7875 - val_loss: 0.5919\n",
            "Epoch 13/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7378 - loss: 0.5920 - val_accuracy: 0.8438 - val_loss: 0.5634\n",
            "Epoch 14/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7991 - loss: 0.5590 - val_accuracy: 0.8438 - val_loss: 0.5270\n",
            "Epoch 15/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8042 - loss: 0.5249 - val_accuracy: 0.8375 - val_loss: 0.4817\n",
            "Epoch 16/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8040 - loss: 0.4873 - val_accuracy: 0.8375 - val_loss: 0.4467\n",
            "Epoch 17/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7910 - loss: 0.4691 - val_accuracy: 0.8250 - val_loss: 0.4212\n",
            "Epoch 18/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8278 - loss: 0.4210 - val_accuracy: 0.8188 - val_loss: 0.4274\n",
            "Epoch 19/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8261 - loss: 0.4077 - val_accuracy: 0.8438 - val_loss: 0.3962\n",
            "Epoch 20/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8255 - loss: 0.4212 - val_accuracy: 0.8250 - val_loss: 0.3870\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8633 - loss: 0.3823  \n",
            "Test Accuracy: 0.8450000286102295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transformer"
      ],
      "metadata": {
        "id": "-KUhvSunb4gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, Add, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Positional encoding function\n",
        "def positional_encoding(seq_len, d_model):\n",
        "    pos = np.arange(seq_len)[:, np.newaxis]\n",
        "    i = np.arange(d_model)[np.newaxis, :]\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    angle_rads = pos * angle_rates\n",
        "    pos_encoding = np.zeros(angle_rads.shape)\n",
        "    pos_encoding[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    pos_encoding[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    pos_encoding = pos_encoding[np.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "# Transformer encoder block\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0.1):\n",
        "    # Layer normalization and multi-head attention\n",
        "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    res = Add()([x, inputs])\n",
        "\n",
        "    # Feed-forward network\n",
        "    x = LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = Dense(ff_dim, activation=\"relu\")(x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    x = Dense(inputs.shape[-1])(x)\n",
        "    return Add()([x, res])\n",
        "\n",
        "# Define model parameters\n",
        "seq_len = 10         # Number of timesteps in each sample\n",
        "d_model = 64         # Model dimension\n",
        "numfeatures = X_train.shape[1]\n",
        "\n",
        "# Input layer\n",
        "inputs = Input(shape=(seq_len, numfeatures))\n",
        "# Project inputs to the desired dimension\n",
        "x = Dense(d_model)(inputs)\n",
        "\n",
        "# Add positional encoding\n",
        "x += positional_encoding(seq_len, d_model)\n",
        "\n",
        "# Stack transformer encoder blocks\n",
        "num_transformer_blocks = 2\n",
        "for _ in range(num_transformer_blocks):\n",
        "    x = transformer_encoder(x, head_size=32, num_heads=4, ff_dim=64, dropout=0.1)\n",
        "\n",
        "# Global pooling and output layer\n",
        "x = GlobalAveragePooling1D()(x)\n",
        "x = Dropout(0.1)(x)\n",
        "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "# Build and compile the model\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Mflh2Y41W1V3",
        "outputId": "a9683206-2e1b-4c2f-b05e-503f08fa536e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m128\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m128\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m33,216\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m128\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │          \u001b[38;5;34m4,160\u001b[0m │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │          \u001b[38;5;34m4,160\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m128\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m33,216\u001b[0m │ layer_normalization_2… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m128\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │          \u001b[38;5;34m4,160\u001b[0m │ layer_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │          \u001b[38;5;34m4,160\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33,216</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33,216</span> │ layer_normalization_2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ layer_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m83,777\u001b[0m (327.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,777</span> (327.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m83,777\u001b[0m (327.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,777</span> (327.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.4993 - loss: 0.8470 - val_accuracy: 0.5125 - val_loss: 0.6790\n",
            "Epoch 2/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5431 - loss: 0.7035 - val_accuracy: 0.4875 - val_loss: 0.7182\n",
            "Epoch 3/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6103 - loss: 0.6616 - val_accuracy: 0.7688 - val_loss: 0.5627\n",
            "Epoch 4/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7513 - loss: 0.5436 - val_accuracy: 0.7937 - val_loss: 0.4481\n",
            "Epoch 5/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7507 - loss: 0.5014 - val_accuracy: 0.6313 - val_loss: 0.6781\n",
            "Epoch 6/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7338 - loss: 0.5145 - val_accuracy: 0.8125 - val_loss: 0.4135\n",
            "Epoch 7/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7615 - loss: 0.4999 - val_accuracy: 0.8375 - val_loss: 0.3948\n",
            "Epoch 8/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8103 - loss: 0.4253 - val_accuracy: 0.7750 - val_loss: 0.5168\n",
            "Epoch 9/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7543 - loss: 0.5147 - val_accuracy: 0.8125 - val_loss: 0.4326\n",
            "Epoch 10/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7904 - loss: 0.4430 - val_accuracy: 0.7750 - val_loss: 0.5363\n",
            "Epoch 11/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8001 - loss: 0.4191 - val_accuracy: 0.8438 - val_loss: 0.3747\n",
            "Epoch 12/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7948 - loss: 0.4048 - val_accuracy: 0.7875 - val_loss: 0.4570\n",
            "Epoch 13/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7345 - loss: 0.5260 - val_accuracy: 0.7937 - val_loss: 0.4539\n",
            "Epoch 14/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7989 - loss: 0.4603 - val_accuracy: 0.7937 - val_loss: 0.4465\n",
            "Epoch 15/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8228 - loss: 0.4254 - val_accuracy: 0.8438 - val_loss: 0.3792\n",
            "Epoch 16/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8026 - loss: 0.4373 - val_accuracy: 0.8125 - val_loss: 0.4002\n",
            "Epoch 17/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7708 - loss: 0.4480 - val_accuracy: 0.7937 - val_loss: 0.4416\n",
            "Epoch 18/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7897 - loss: 0.4198 - val_accuracy: 0.8438 - val_loss: 0.3674\n",
            "Epoch 19/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8064 - loss: 0.4384 - val_accuracy: 0.7937 - val_loss: 0.4578\n",
            "Epoch 20/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8026 - loss: 0.3948 - val_accuracy: 0.8438 - val_loss: 0.3770\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8357 - loss: 0.3697 \n",
            "Test accuracy: 0.8299999833106995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SSQaXsMUpMa",
        "outputId": "fc0da149-3ce5-4c29-ddb4-610ef1669449"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import keras_tuner as kt\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    # Input layer with tunable number of neurons\n",
        "    model.add(Dense(units=hp.Int('units_input', min_value=32, max_value=256, step=32),\n",
        "                    activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    model.add(Dropout(rate=hp.Float('dropout_input', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Add 1 to 3 hidden layers\n",
        "    for i in range(hp.Int('num_layers', 1, 3)):\n",
        "        model.add(Dense(units=hp.Int(f'units_{i}', min_value=32, max_value=256, step=32),\n",
        "                        activation='relu'))\n",
        "        model.add(Dropout(rate=hp.Float(f'dropout_{i}', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Output layer for binary classification\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
        "                      hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=3,\n",
        "    directory='qkd_tuning',\n",
        "    project_name='attack_detection'\n",
        ")\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=50, validation_split=0.2)\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best model test accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDZy9rFZUiFs",
        "outputId": "99d53e02-a204-4ce9-b024-ac3b8208e75f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 54s]\n",
            "val_accuracy: 0.84375\n",
            "\n",
            "Best val_accuracy So Far: 0.84375\n",
            "Total elapsed time: 00h 07m 45s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8357 - loss: 0.6339  \n",
            "Best model test accuracy: 0.8299999833106995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Reinforcement Learning for Dynamic Key Rate Allocation\n",
        "Instead of fixed QKD key rates, we can use reinforcement learning (RL) to optimize transmission rates based on channel conditions.\n",
        "\n",
        "Approach:\n",
        "\n",
        "Define the state as channel conditions and noise levels.\n",
        "Define actions as key rate adjustments.\n",
        "Use Q-learning to maximize secure key generation.\n",
        "### Step 4: RL-Based Key Rate Allocation"
      ],
      "metadata": {
        "id": "gNOG8P6pufM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "class QKDSimulator(gym.Env):\n",
        "    def __init__(self):\n",
        "        self.state = 0.5  # QBER as state\n",
        "        self.action_space = np.array([0.1, 0.2, 0.3])  # Adjust key rate\n",
        "        self.reward = 0\n",
        "\n",
        "    def step(self, action):\n",
        "        self.state += np.random.normal(0, 0.01)  # Simulate noise variation\n",
        "        self.reward = -abs(self.state - action)  # Reward based on key rate efficiency\n",
        "        return self.state, self.reward\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = 0.5\n",
        "        return self.state\n",
        "\n",
        "env = QKDSimulator()\n",
        "for _ in range(10):\n",
        "    action = np.random.choice(env.action_space)\n",
        "    state, reward = env.step(action)\n",
        "    print(f\"Action: {action}, New QBER: {state:.3f}, Reward: {reward:.3f}\")\n"
      ],
      "metadata": {
        "id": "wBLKSCAbupsW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "651a8085-5f3f-43be-9474-8aefdfc91a4a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action: 0.1, New QBER: 0.490, Reward: -0.390\n",
            "Action: 0.3, New QBER: 0.483, Reward: -0.183\n",
            "Action: 0.1, New QBER: 0.483, Reward: -0.383\n",
            "Action: 0.1, New QBER: 0.479, Reward: -0.379\n",
            "Action: 0.1, New QBER: 0.488, Reward: -0.388\n",
            "Action: 0.1, New QBER: 0.472, Reward: -0.372\n",
            "Action: 0.3, New QBER: 0.483, Reward: -0.183\n",
            "Action: 0.2, New QBER: 0.485, Reward: -0.285\n",
            "Action: 0.1, New QBER: 0.487, Reward: -0.387\n",
            "Action: 0.3, New QBER: 0.498, Reward: -0.198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion & Next Steps\n",
        "This project integrates AI into QKD for attack detection, error correction, and dynamic key rate optimization.\n",
        "Possible improvements:\n",
        "* Implement deep learning models for attack detection.\n",
        "* Test on real quantum hardware using IBMQ.\n",
        "* Extend reinforcement learning for network-wide QKD optimization.\n"
      ],
      "metadata": {
        "id": "kkWdApdXu1Ff"
      }
    }
  ]
}

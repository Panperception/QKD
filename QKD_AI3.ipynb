{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "QKD-AI3.ipynb",
      "history_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMGX444tmTw8BT7cB7iyR0t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Panperception/QKD/blob/main/QKD_AI3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install required libs"
      ],
      "metadata": {
        "id": "LS5VEJZg1xmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip uninstall qiskit\n",
        "!pip install pyqmc\n",
        "!pip install qiskit\n",
        "!pip install qiskit-aer\n",
        "!pip install qiskit-algorithms\n",
        "!pip install qiskit-nature\n",
        "!pip install qutip\n",
        "!pip install ase\n",
        "!pip install scipy\n",
        "!nvcc --version"
      ],
      "metadata": {
        "id": "8QJMbule4KQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A whole set of tests\n",
        "\n",
        "Below is a single, self‐contained Python script that integrates data preparation for a shared synthetic dataset and runs experiments for several advanced QKD–AI scenarios. In this unified example, we generate synthetic data for multiple tasks (error correction parameter estimation, quantum feedback control, decoy‐state optimization, and multi‐modal attack detection) and also include experiments for a reinforcement learning (RL)–based key rate optimizer and a genetic algorithm for end‐to‐end protocol parameter optimization.\n",
        "\n"
      ],
      "metadata": {
        "id": "efA7A5yX18jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable_baselines3\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Input, LayerNormalization, MultiHeadAttention, Add, GlobalAveragePooling1D, Concatenate\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import gym\n",
        "from gym import spaces\n",
        "from stable_baselines3 import DQN\n",
        "from deap import base, creator, tools, algorithms\n",
        "\n",
        "# -------------------------\n",
        "# 0. Set Random Seeds\n",
        "# -------------------------\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# -------------------------\n",
        "# 1. Data Preparation\n",
        "# -------------------------\n",
        "# We define several synthetic datasets to simulate different aspects of a QKD system.\n",
        "\n",
        "def create_error_correction_dataset(num_samples=1000):\n",
        "    # Features: [channel_loss, noise, QBER, misc_stat]\n",
        "    X = np.random.rand(num_samples, 4)\n",
        "    # Label: optimal error correction rate (higher when QBER is low)\n",
        "    y = 1 - X[:, 2] + 0.05 * np.random.randn(num_samples)\n",
        "    return X, y\n",
        "\n",
        "def create_qber_series_dataset(num_series=500, timesteps=20):\n",
        "    # Each sample is a time series representing measured QBER over time.\n",
        "    X = []\n",
        "    y = []\n",
        "    for _ in range(num_series):\n",
        "        base = np.random.rand() * 0.1  # baseline QBER\n",
        "        noise = np.random.randn(timesteps) * 0.01\n",
        "        series = base + noise\n",
        "        # Control signal: corrective value to bring the last measurement toward target (e.g., 0.02)\n",
        "        target = 0.02\n",
        "        control = -(series[-1] - target)\n",
        "        X.append(series.reshape(timesteps, 1))\n",
        "        y.append(control)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def create_decoy_dataset(num_samples=1000):\n",
        "    # Features: [channel_loss, noise_level]\n",
        "    X = np.random.rand(num_samples, 2)\n",
        "    # Label: optimal decoy intensity (for simulation, we assume an approximately linear relation)\n",
        "    y = 0.5 + 0.2*(X[:, 0] - 0.5) + 0.05*np.random.randn(num_samples)\n",
        "    return X, y\n",
        "\n",
        "def create_multimodal_dataset(num_samples=1000):\n",
        "    # Create three modalities:\n",
        "    #  - QBER features (5 values)\n",
        "    #  - Detector noise stats (3 values)\n",
        "    #  - Timing jitter (2 values)\n",
        "    X_qber = np.random.rand(num_samples, 5)\n",
        "    X_noise = np.random.rand(num_samples, 3)\n",
        "    X_jitter = np.random.rand(num_samples, 2)\n",
        "    # Binary label: 0 (normal) or 1 (attack)\n",
        "    y = np.random.randint(0, 2, size=(num_samples, 1))\n",
        "    return (X_qber, X_noise, X_jitter), y\n",
        "\n",
        "# Generate datasets\n",
        "X_ec, y_ec = create_error_correction_dataset()\n",
        "X_qber_series, y_qber_series = create_qber_series_dataset()\n",
        "X_decoy, y_decoy = create_decoy_dataset()\n",
        "(X_mm_qber, X_mm_noise, X_mm_jitter), y_mm = create_multimodal_dataset()\n",
        "\n",
        "# Split datasets for supervised tasks (error correction, decoy, multimodal detection)\n",
        "X_ec_train, X_ec_test, y_ec_train, y_ec_test = train_test_split(X_ec, y_ec, test_size=0.2, random_state=42)\n",
        "X_decoy_train, X_decoy_test, y_decoy_train, y_decoy_test = train_test_split(X_decoy, y_decoy, test_size=0.2, random_state=42)\n",
        "X_mm_qber_train, X_mm_qber_test, y_mm_train = train_test_split(X_mm_qber, y_mm, test_size=0.2, random_state=42)\n",
        "X_mm_noise_train, X_mm_noise_test, _ = train_test_split(X_mm_noise, y_mm, test_size=0.2, random_state=42)\n",
        "X_mm_jitter_train, X_mm_jitter_test, _ = train_test_split(X_mm_jitter, y_mm, test_size=0.2, random_state=42)\n",
        "\n",
        "# -------------------------\n",
        "# 2. Experiment Modules\n",
        "# -------------------------\n",
        "\n",
        "# 2.1. RL: Real-Time Dynamic Key Rate Optimization Environment\n",
        "class QKDEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(QKDEnv, self).__init__()\n",
        "        # State: [channel_loss, noise_level] between 0 and 1\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(2,), dtype=np.float32)\n",
        "        # Action: modulation parameter in [0,1]\n",
        "        self.action_space = spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)\n",
        "        self.state = np.array([0.5, 0.5])\n",
        "        self.step_count = 0\n",
        "\n",
        "    def step(self, action):\n",
        "        channel_loss, noise = self.state\n",
        "        modulation = action[0]\n",
        "        # Simulated QBER: lower if modulation is higher\n",
        "        qber = noise * (1 - modulation) + np.random.rand()*0.01\n",
        "        # Key rate: ideally higher when modulation is high and QBER is low\n",
        "        key_rate = modulation * (1 - qber)\n",
        "        reward = key_rate\n",
        "        # Update state with small random fluctuation\n",
        "        self.state = np.clip(self.state + np.random.randn(2)*0.01, 0, 1)\n",
        "        self.step_count += 1\n",
        "        done = self.step_count > 100\n",
        "        return self.state, reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = np.array([0.5, 0.5])\n",
        "        self.step_count = 0\n",
        "        return self.state\n",
        "\n",
        "# 2.2. Adaptive Error Correction Parameter Estimation Model\n",
        "def build_error_correction_model():\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(4,)),\n",
        "        Dropout(0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# 2.3. Quantum Feedback Control Using LSTM Model\n",
        "def build_feedback_model(timesteps, features=1):\n",
        "    model = Sequential([\n",
        "        LSTM(32, input_shape=(timesteps, features)),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# 2.4. Adaptive Decoy-State Protocol Predictor\n",
        "def build_decoy_model():\n",
        "    model = Sequential([\n",
        "        Dense(32, activation='relu', input_shape=(2,)),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# 2.5. Multi-Modal Attack Detection Model\n",
        "def build_multimodal_model():\n",
        "    input_qber = Input(shape=(5,))\n",
        "    input_noise = Input(shape=(3,))\n",
        "    input_jitter = Input(shape=(2,))\n",
        "\n",
        "    x1 = Dense(16, activation='relu')(input_qber)\n",
        "    x2 = Dense(16, activation='relu')(input_noise)\n",
        "    x3 = Dense(16, activation='relu')(input_jitter)\n",
        "\n",
        "    combined = Concatenate()([x1, x2, x3])\n",
        "    x = Dense(32, activation='relu')(combined)\n",
        "    x = Dropout(0.2)(x)\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=[input_qber, input_noise, input_jitter], outputs=output)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 2.6. End-to-End QKD Protocol Design via Genetic Algorithm\n",
        "def optimize_protocol_parameters():\n",
        "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "    toolbox = base.Toolbox()\n",
        "    # Parameters: [modulation_index, decoy_intensity, error_corr_rate]\n",
        "    toolbox.register(\"attr_float\", random.uniform, 0, 1)\n",
        "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, 3)\n",
        "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "    def evaluate_protocol(individual):\n",
        "        modulation_index, decoy_intensity, error_corr_rate = individual\n",
        "        key_rate = modulation_index * (1 - abs(decoy_intensity - 0.5)) * error_corr_rate\n",
        "        return (key_rate,)\n",
        "    toolbox.register(\"evaluate\", evaluate_protocol)\n",
        "    toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
        "    toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.1, indpb=0.2)\n",
        "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "    population = toolbox.population(n=50)\n",
        "    algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=20, verbose=False)\n",
        "    best_ind = tools.selBest(population, 1)[0]\n",
        "    return best_ind, evaluate_protocol(best_ind)[0]\n",
        "\n",
        "# -------------------------\n",
        "# 3. Running All Experiments\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Experiment 1: RL for Dynamic Key Rate Optimization\n",
        "    print(\"=== RL: Real-Time Dynamic Key Rate Optimization ===\")\n",
        "    env = QKDEnv()\n",
        "    rl_model = DQN('MlpPolicy', env, verbose=0)\n",
        "    rl_model.learn(total_timesteps=5000)\n",
        "    state = env.reset()\n",
        "    for i in range(10):\n",
        "        action, _ = rl_model.predict(state)\n",
        "        state, reward, done, _ = env.step(action)\n",
        "        print(f\"Step {i+1}: State = {state}, Reward = {reward:.4f}\")\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # Experiment 2: Adaptive Error Correction Parameter Estimation\n",
        "    print(\"\\n=== Adaptive Error Correction Parameter Estimation ===\")\n",
        "    ec_model = build_error_correction_model()\n",
        "    ec_model.fit(X_ec_train, y_ec_train, epochs=30, batch_size=32, validation_data=(X_ec_test, y_ec_test), verbose=0)\n",
        "    ec_loss, ec_mae = ec_model.evaluate(X_ec_test, y_ec_test, verbose=0)\n",
        "    print(\"Error Correction Model Test MAE:\", ec_mae)\n",
        "\n",
        "    # Experiment 3: Quantum Feedback Control with LSTM\n",
        "    print(\"\\n=== Quantum Feedback Control (LSTM) ===\")\n",
        "    timesteps = X_qber_series.shape[1]\n",
        "    feedback_model = build_feedback_model(timesteps, features=1)\n",
        "    feedback_model.fit(X_qber_series, y_qber_series, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
        "    fb_loss = feedback_model.evaluate(X_qber_series, y_qber_series, verbose=0)\n",
        "    print(\"Feedback Model Loss:\", fb_loss)\n",
        "\n",
        "    # Experiment 4: Adaptive Decoy-State Protocol Optimization Predictor\n",
        "    print(\"\\n=== Adaptive Decoy-State Protocol Optimization ===\")\n",
        "    decoy_model = build_decoy_model()\n",
        "    decoy_model.fit(X_decoy_train, y_decoy_train, epochs=30, batch_size=32, validation_data=(X_decoy_test, y_decoy_test), verbose=0)\n",
        "    decoy_loss = decoy_model.evaluate(X_decoy_test, y_decoy_test, verbose=0)\n",
        "    print(\"Decoy Model Loss:\", decoy_loss)\n",
        "\n",
        "    # Experiment 5: Multi-Modal Attack Detection\n",
        "    print(\"\\n=== Multi-Modal Attack Detection ===\")\n",
        "    mm_model = build_multimodal_model()\n",
        "    mm_model.fit([X_mm_qber_train, X_mm_noise_train, X_mm_jitter_train], y_mm_train, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
        "    mm_loss, mm_acc = mm_model.evaluate([X_mm_qber_test, X_mm_noise_test, X_mm_jitter_test], y_mm_test, verbose=0)\n",
        "    print(\"Multi-Modal Model Test Accuracy:\", mm_acc)\n",
        "\n",
        "    # Experiment 6: End-to-End QKD Protocol Design via Genetic Algorithm\n",
        "    print(\"\\n=== End-to-End QKD Protocol Design via Genetic Algorithm ===\")\n",
        "    best_protocol, best_key_rate = optimize_protocol_parameters()\n",
        "    print(\"Best protocol parameters:\", best_protocol)\n",
        "    print(\"Achieved simulated key rate:\", best_key_rate)\n"
      ],
      "metadata": {
        "id": "DMlkNB-Z16Ep",
        "outputId": "87499c1c-20bc-458e-d19e-fe7568e0247c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.0.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.5.1+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.5.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'deap'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-55d1f6a03eb2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# -------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deap'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A more sophisticated test\n",
        "Below is an example of a more comprehensive simulation framework that integrates a more realistic QKD‐system model with several AI modules. In this script, we simulate a decoy‐state QKD system using a simplified—but more realistic—model based on Poissonian photon statistics, channel loss, dark counts, and noise. Then, we use the simulation to generate sophisticated data that feed into several experiments: an RL‐based key rate optimizer, an adaptive error‐correction estimator, an LSTM-based feedback controller, a decoy-state predictor, a multi‐modal attack detection module, and a genetic algorithm for protocol parameter optimization.\n",
        "\n",
        "**Note: This simulation is still a simplified “toy” model for illustration. In practice you may need to replace or extend the functions (e.g. the QBER and key rate calculations) with models derived from your experimental QKD system.**"
      ],
      "metadata": {
        "id": "qqGMGQm02bRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "g9RZFHyv30tO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deap # Install the missing 'deap' library.\n",
        "!pip install 'shimmy>=2.0' # Install shimmy to support OpenAI Gym environments with SB3\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Input, LayerNormalization, MultiHeadAttention, Add, GlobalAveragePooling1D, Concatenate\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import gym\n",
        "from gym import spaces\n",
        "from stable_baselines3 import DQN\n",
        "from deap import base, creator, tools, algorithms\n",
        "import math\n",
        "\n",
        "# -------------------------\n",
        "# 0. Set Random Seeds\n",
        "# -------------------------\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# -------------------------\n",
        "# 1. Realistic QKD Simulation Functions\n",
        "# -------------------------\n",
        "def poisson_photon_number(mu):\n",
        "    \"\"\"Simulate photon number from a Poisson distribution with mean mu.\"\"\"\n",
        "    return np.random.poisson(mu)\n",
        "\n",
        "def simulate_qkd_run(mu, t, dark_count=1e-5, noise_std=0.01, attack=False):\n",
        "    \"\"\"\n",
        "    Simulate one round of decoy-state QKD.\n",
        "\n",
        "    Parameters:\n",
        "      mu: average photon number (signal intensity)\n",
        "      t: channel transmittance (0 to 1)\n",
        "      dark_count: dark count probability per detector\n",
        "      noise_std: standard deviation of noise in detection\n",
        "      attack: if True, simulate an attack (e.g., intercept-resend increases errors)\n",
        "\n",
        "    Returns:\n",
        "      qber: Quantum Bit Error Rate (float between 0 and 1)\n",
        "      key_rate: secure key rate (a simplified function)\n",
        "      decoy_state: simulated decoy measurement (could be the observed intensity)\n",
        "    \"\"\"\n",
        "    # Simulate the number of photons sent in a pulse\n",
        "    n_photons = poisson_photon_number(mu)\n",
        "    # Photons transmitted through channel: each photon survives with probability t\n",
        "    n_detected = np.sum(np.random.rand(n_photons) < t)\n",
        "\n",
        "    # Dark counts: simulate extra counts (assuming a fixed probability per pulse)\n",
        "    dark = 1 if np.random.rand() < dark_count else 0\n",
        "\n",
        "    # The total counts at Bob\n",
        "    total_counts = n_detected + dark\n",
        "    # Base error probability due to noise\n",
        "    base_error = noise_std\n",
        "    # If an attacker is present, errors increase (e.g., by 0.05)\n",
        "    attack_error = 0.05 if attack else 0.0\n",
        "\n",
        "    # QBER: if total_counts > 0, errors occur with probability base_error+attack_error\n",
        "    if total_counts > 0:\n",
        "        errors = np.random.binomial(total_counts, base_error + attack_error)\n",
        "        qber = errors / total_counts\n",
        "    else:\n",
        "        qber = 0.5  # if no detection, assume maximum uncertainty\n",
        "\n",
        "    # Secure key rate estimation using a simple model: key_rate = total_counts*(1 - H(qber))\n",
        "    # H(x): binary entropy function.\n",
        "    def binary_entropy(x):\n",
        "        if x==0 or x==1:\n",
        "            return 0.0\n",
        "        return -x*math.log2(x) - (1-x)*math.log2(1-x)\n",
        "\n",
        "    key_rate = total_counts * (1 - binary_entropy(qber))\n",
        "    # Simulate decoy state measurement as observed intensity with noise\n",
        "    decoy_state = mu + np.random.randn()*0.05\n",
        "    return qber, key_rate, decoy_state\n",
        "\n",
        "def generate_qkd_dataset(num_samples=1000, attack_ratio=0.2):\n",
        "    \"\"\"\n",
        "    Generate a dataset for supervised learning tasks.\n",
        "    Each sample includes channel parameters and simulation outputs.\n",
        "\n",
        "    Returns:\n",
        "      X: features matrix including [mu, t, dark_count, noise_std, decoy_state, attack_flag]\n",
        "      y_qber: simulated QBER\n",
        "      y_key_rate: simulated key rate\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y_qber = []\n",
        "    y_key_rate = []\n",
        "    for _ in range(num_samples):\n",
        "        # Randomly choose parameters in realistic ranges:\n",
        "        mu = np.random.uniform(0.1, 1.0)           # signal intensity\n",
        "        t = np.random.uniform(0.1, 0.9)              # channel transmittance\n",
        "        dark = 1e-5                                  # dark count (fixed for now)\n",
        "        noise_std = np.random.uniform(0.005, 0.02)     # noise level\n",
        "        attack_flag = 1 if np.random.rand() < attack_ratio else 0\n",
        "        qber, key_rate, decoy_state = simulate_qkd_run(mu, t, dark, noise_std, attack=bool(attack_flag))\n",
        "        features = [mu, t, dark, noise_std, decoy_state, attack_flag]\n",
        "        X.append(features)\n",
        "        y_qber.append(qber)\n",
        "        y_key_rate.append(key_rate)\n",
        "    return np.array(X), np.array(y_qber), np.array(y_key_rate)\n",
        "\n",
        "# Generate a shared QKD dataset\n",
        "X_qkd, y_qkd, key_rates = generate_qkd_dataset(num_samples=2000, attack_ratio=0.3)\n",
        "# For some supervised tasks, we can use different target variables:\n",
        "#  - For error correction estimation, we might use y_qkd (QBER)\n",
        "#  - For decoy-state optimization, we might use decoy_state as part of X and key_rates\n",
        "\n",
        "# Split the QKD dataset (we'll use it for training some of our modules)\n",
        "X_qkd_train, X_qkd_test, y_qkd_train, y_qkd_test = train_test_split(X_qkd, y_qkd, test_size=0.2, random_state=42)\n",
        "\n",
        "# -------------------------\n",
        "# 2. Experiment Modules (Refined with QKD Simulation Data)\n",
        "# -------------------------\n",
        "\n",
        "# 2.1. RL Environment for Dynamic Key Rate Optimization\n",
        "class QKDEnvRealistic(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(QKDEnvRealistic, self).__init__()\n",
        "        # State: [mu, t, noise_std] - basic channel parameters\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(3,), dtype=np.float32)\n",
        "        # Action: modulation adjustment in [0,1] that might affect key rate\n",
        "        self.action_space = spaces.Discrete(10)\n",
        "        # Initialize state with random parameters\n",
        "        self.state = np.array([0.5, 0.5, 0.01])\n",
        "        self.step_count = 0\n",
        "\n",
        "    def step(self, action):\n",
        "        mu, t, noise = self.state\n",
        "        modulation = action / (self.action_space.n - 1)\n",
        "        # We assume modulation improves effective transmittance:\n",
        "        effective_t = np.clip(t * modulation, 0, 1)\n",
        "        # Simulate one round of QKD with these parameters (no attack in RL env)\n",
        "        qber, key_rate, _ = simulate_qkd_run(mu, effective_t, dark_count=1e-5, noise_std=noise, attack=False)\n",
        "        # Reward: key_rate normalized by mu for example\n",
        "        reward = key_rate / mu\n",
        "        # Update state with slight fluctuation (simulate slowly varying channel)\n",
        "        self.state = np.clip(self.state + np.random.randn(3)*0.005, 0, 1)\n",
        "        self.step_count += 1\n",
        "        done = self.step_count > 100\n",
        "        return self.state, reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = np.array([0.5, 0.5, 0.01])\n",
        "        self.step_count = 0\n",
        "        return self.state\n",
        "\n",
        "# 2.2. Adaptive Error Correction Parameter Estimation Model\n",
        "# Here we use the QKD simulation dataset: features: [mu, t, dark, noise, decoy, attack_flag]\n",
        "# and target: y_qkd (QBER)\n",
        "def build_error_correction_model():\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(X_qkd_train.shape[1],)),\n",
        "        Dropout(0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# 2.3. Quantum Feedback Control Using LSTM\n",
        "# We simulate a time series by generating a sequence of QBER values from consecutive QKD runs.\n",
        "def generate_qber_series_from_simulation(num_series=500, timesteps=20):\n",
        "    X_series = []\n",
        "    y_feedback = []\n",
        "    for _ in range(num_series):\n",
        "        series = []\n",
        "        # Start with a random state\n",
        "        mu = np.random.uniform(0.2, 0.8)\n",
        "        t = np.random.uniform(0.3, 0.9)\n",
        "        noise = np.random.uniform(0.005, 0.02)\n",
        "        for _ in range(timesteps):\n",
        "            qber, _, _ = simulate_qkd_run(mu, t, dark_count=1e-5, noise_std=noise, attack=False)\n",
        "            series.append(qber)\n",
        "            # Let channel parameters drift slowly\n",
        "            mu = np.clip(mu + np.random.randn()*0.01, 0.2, 0.8)\n",
        "            t = np.clip(t + np.random.randn()*0.01, 0.3, 0.9)\n",
        "        series = np.array(series)\n",
        "        # Desired control: bring last QBER to a target (e.g., 0.02)\n",
        "        target = 0.02\n",
        "        control = -(series[-1] - target)\n",
        "        X_series.append(series.reshape(timesteps, 1))\n",
        "        y_feedback.append(control)\n",
        "    return np.array(X_series), np.array(y_feedback)\n",
        "\n",
        "X_qber_series, y_feedback = generate_qber_series_from_simulation()\n",
        "\n",
        "def build_feedback_model(timesteps, features=1):\n",
        "    model = Sequential([\n",
        "        LSTM(32, input_shape=(timesteps, features)),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# 2.4. Adaptive Decoy-State Protocol Predictor\n",
        "# Using our QKD dataset, we use the decoy measurement (column index 4) as part of features.\n",
        "# Here, we try to predict the optimal decoy intensity given channel loss and noise.\n",
        "def build_decoy_model():\n",
        "    # Input: [t, noise] from our QKD features (columns 1 and 3)\n",
        "    model = Sequential([\n",
        "        Dense(32, activation='relu', input_shape=(2,)),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# 2.5. Multi-Modal Attack Detection Model\n",
        "# For this example, we simulate multi-modal data from the QKD simulation.\n",
        "# We create three modalities:\n",
        "#   - QBER series (5 values): simulated over 5 runs\n",
        "#   - Detector noise: random vector of 3 values\n",
        "#   - Timing jitter: random vector of 2 values\n",
        "def create_multimodal_qkd_dataset(num_samples=1000):\n",
        "    X_qber = np.random.rand(num_samples, 5) * 0.1  # QBER values around 0.0-0.1\n",
        "    X_noise = np.random.rand(num_samples, 3) * 0.02  # noise levels\n",
        "    X_jitter = np.random.rand(num_samples, 2) * 0.005  # jitter in seconds\n",
        "    # Label: simulate attack if average QBER > threshold or high noise (simple rule)\n",
        "    y = ((X_qber.mean(axis=1) > 0.05) | (X_noise.mean(axis=1) > 0.015)).astype(int).reshape(-1, 1)\n",
        "    return (X_qber, X_noise, X_jitter), y\n",
        "\n",
        "(X_mm_qber, X_mm_noise, X_mm_jitter), y_mm = create_multimodal_qkd_dataset()\n",
        "X_mm_qber_train, X_mm_qber_test, y_mm_train, y_mm_test = train_test_split(X_mm_qber, y_mm, test_size=0.2, random_state=42)\n",
        "# Added y_mm_test to capture the fourth return value from train_test_split\n",
        "X_mm_noise_train, X_mm_noise_test, y_mm_noise_train, y_mm_noise_test_ = train_test_split(X_mm_noise, y_mm, test_size=0.2, random_state=42)\n",
        "X_mm_jitter_train, X_mm_jitter_test, y_mm_jitter_train, y_mm_jitter_test = train_test_split(X_mm_jitter, y_mm, test_size=0.2, random_state=42)\n",
        "\n",
        "def build_multimodal_model():\n",
        "    input_qber = Input(shape=(5,))\n",
        "    input_noise = Input(shape=(3,))\n",
        "    input_jitter = Input(shape=(2,))\n",
        "\n",
        "    x1 = Dense(16, activation='relu')(input_qber)\n",
        "    x2 = Dense(16, activation='relu')(input_noise)\n",
        "    x3 = Dense(16, activation='relu')(input_jitter)\n",
        "\n",
        "    combined = Concatenate()([x1, x2, x3])\n",
        "    x = Dense(32, activation='relu')(combined)\n",
        "    x = Dropout(0.2)(x)\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=[input_qber, input_noise, input_jitter], outputs=output)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 2.6. End-to-End QKD Protocol Design via Genetic Algorithm\n",
        "def optimize_protocol_parameters():\n",
        "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "    toolbox = base.Toolbox()\n",
        "    # Parameters: [modulation_index, decoy_intensity, error_corr_rate]\n",
        "    toolbox.register(\"attr_float\", random.uniform, 0, 1)\n",
        "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, 3)\n",
        "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "    def evaluate_protocol(individual):\n",
        "        modulation_index, decoy_intensity, error_corr_rate = individual\n",
        "        # Use a more realistic key rate function: assume key_rate depends on channel transmittance and QBER.\n",
        "        # Here we use a simulated formula: key_rate = modulation_index * (1 - abs(decoy_intensity - 0.5)) * error_corr_rate\n",
        "        return (modulation_index * (1 - abs(decoy_intensity - 0.5)) * error_corr_rate,)\n",
        "    toolbox.register(\"evaluate\", evaluate_protocol)\n",
        "    toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
        "    toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.1, indpb=0.2)\n",
        "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "    population = toolbox.population(n=50)\n",
        "    algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=20, verbose=False)\n",
        "    best_ind = tools.selBest(population, 1)[0]\n",
        "    return best_ind, evaluate_protocol(best_ind)[0]\n",
        "\n",
        "# -------------------------\n",
        "# 3. Running the Complete Simulation Framework\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Experiment 1: RL for Dynamic Key Rate Optimization (Realistic QKD Env)\n",
        "    print(\"=== RL: Real-Time Dynamic Key Rate Optimization (Realistic) ===\")\n",
        "    env = QKDEnvRealistic()\n",
        "    rl_model = DQN('MlpPolicy', env, verbose=0)\n",
        "    rl_model.learn(total_timesteps=5000)\n",
        "    state = env.reset()\n",
        "    for i in range(10):\n",
        "        action, _ = rl_model.predict(state)\n",
        "        state, reward, done, _ = env.step(action)\n",
        "        print(f\"Step {i+1}: State = {state}, Reward = {reward:.4f}\")\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # Experiment 2: Adaptive Error Correction Parameter Estimation (Predict QBER)\n",
        "    print(\"\\n=== Adaptive Error Correction Parameter Estimation ===\")\n",
        "    ec_model = build_error_correction_model()\n",
        "    ec_model.fit(X_qkd_train, y_qkd_train, epochs=30, batch_size=32, validation_split=0.2, verbose=0)\n",
        "    ec_loss, ec_mae = ec_model.evaluate(X_qkd_test, y_qkd_test, verbose=0)\n",
        "    print(\"Error Correction Model Test MAE (QBER prediction):\", ec_mae)\n",
        "\n",
        "    # Experiment 3: Quantum Feedback Control with LSTM\n",
        "    print(\"\\n=== Quantum Feedback Control (LSTM) ===\")\n",
        "    timesteps = X_qber_series.shape[1]\n",
        "    feedback_model = build_feedback_model(timesteps, features=1)\n",
        "    feedback_model.fit(X_qber_series, y_feedback, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
        "    fb_loss = feedback_model.evaluate(X_qber_series, y_feedback, verbose=0)\n",
        "    print(\"Feedback Model Loss:\", fb_loss)\n",
        "\n",
        "    # Experiment 4: Adaptive Decoy-State Protocol Optimization Predictor\n",
        "    print(\"\\n=== Adaptive Decoy-State Protocol Optimization ===\")\n",
        "    # For decoy model, use features: channel transmittance and noise (columns 1 and 3 from X_qkd)\n",
        "    X_decoy_features = X_qkd[:, [1, 3]]\n",
        "    X_decoy_train, X_decoy_test, y_decoy_train, y_decoy_test = train_test_split(X_decoy_features, X_qkd[:, 4], test_size=0.2, random_state=42)\n",
        "    decoy_model = build_decoy_model()\n",
        "    decoy_model.fit(X_decoy_train, y_decoy_train, epochs=30, batch_size=32, validation_data=(X_decoy_test, y_decoy_test), verbose=0)\n",
        "    decoy_loss = decoy_model.evaluate(X_decoy_test, y_decoy_test, verbose=0)\n",
        "    print(\"Decoy Model Loss:\", decoy_loss)\n",
        "\n",
        "    # Experiment 5: Multi-Modal Attack Detection\n",
        "    print(\"\\n=== Multi-Modal Attack Detection ===\")\n",
        "    mm_model = build_multimodal_model()\n",
        "    mm_model.fit([X_mm_qber_train, X_mm_noise_train, X_mm_jitter_train], y_mm_train, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
        "    mm_loss, mm_acc = mm_model.evaluate([X_mm_qber_test, X_mm_noise_test, X_mm_jitter_test], y_mm_test, verbose=0)\n",
        "    print(\"Multi-Modal Model Test Accuracy:\", mm_acc)\n",
        "\n",
        "    # Experiment 6: End-to-End QKD Protocol Design via Genetic Algorithm\n",
        "    print(\"\\n=== End-to-End QKD Protocol Design via Genetic Algorithm ===\")\n",
        "    best_protocol, best_key_rate = optimize_protocol_parameters()\n",
        "    print(\"Best protocol parameters:\", best_protocol)\n",
        "    print(\"Achieved simulated key rate:\", best_key_rate)\n",
        "\n"
      ],
      "metadata": {
        "id": "55ehhmqu11S0",
        "outputId": "fe994bd5-4527-4925-d8b1-733839a1d586",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deap in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deap) (1.26.4)\n",
            "Requirement already satisfied: shimmy>=2.0 in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from shimmy>=2.0) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a1 in /usr/local/lib/python3.11/dist-packages (from shimmy>=2.0) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (0.0.4)\n",
            "=== RL: Real-Time Dynamic Key Rate Optimization (Realistic) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: State = [0.50288996 0.49922139 0.00881875], Reward = 2.0000\n",
            "Step 2: State = [0.49744173 0.498462   0.01017799], Reward = 1.9885\n",
            "Step 3: State = [0.50382804 0.50063855 0.01086841], Reward = 0.0000\n",
            "Step 4: State = [0.51278965 0.50023901 0.01666742], Reward = 0.0000\n",
            "Step 5: State = [0.51270177 0.4913049  0.01345244], Reward = 0.0000\n",
            "Step 6: State = [0.52233217 0.49112127 0.01951832], Reward = 0.0000\n",
            "Step 7: State = [0.52526621 0.48565861 0.0174828 ], Reward = 0.0000\n",
            "Step 8: State = [0.52560537 0.49296236 0.01649681], Reward = 0.0000\n",
            "Step 9: State = [0.52966161 0.49379049 0.01376418], Reward = 0.0000\n",
            "Step 10: State = [0.53399081 0.48391635 0.01098973], Reward = 1.8880\n",
            "\n",
            "=== Adaptive Error Correction Parameter Estimation ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error Correction Model Test MAE (QBER prediction): 0.14839009940624237\n",
            "\n",
            "=== Quantum Feedback Control (LSTM) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feedback Model Loss: 6.15660464973189e-05\n",
            "\n",
            "=== Adaptive Decoy-State Protocol Optimization ===\n",
            "Decoy Model Loss: 0.07091071456670761\n",
            "\n",
            "=== Multi-Modal Attack Detection ===\n",
            "Multi-Modal Model Test Accuracy: 0.9350000023841858\n",
            "\n",
            "=== End-to-End QKD Protocol Design via Genetic Algorithm ===\n",
            "Best protocol parameters: [1.394823357023787, 0.5315929434425318, 1.7839053948323698]\n",
            "Achieved simulated key rate: 2.409622309790183\n"
          ]
        }
      ]
    }
  ]
}